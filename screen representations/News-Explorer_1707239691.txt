Description for the News-Explorer application:
Window named 'Latest News – 1 unread' with state 'None' at position (0, 0).
  ScrollArea named 'None' with state 'None' at position (0, 0).
    List named 'None' with state 'None' at position (0, 0).
      List named 'None' with state 'None' at position (0, 0).
        Group named 'None' with state 'None' at position (0, 0).
          StaticText named 'None' with state 'Today' at position (52, 124).
          StaticText named 'None' with state '95 items' at position (2160, 130).
        Group named 'None' with state 'None' at position (38, 194).
          Group named 'None' with state 'None' at position (38, 194).
          Image named 'None' with state 'None' at position (1116, 1116).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Seeking ideas for my final year project [P]' at position (54, 230).
          StaticText named 'None' with state 'Machine Learning' at position (54, 1110).
          StaticText named 'None' with state 'Today, 18:13' at position (982, 1110).
          StaticText named 'None' with state 'Currently brainstorming ideas for my final year project and looking for an inspiration! Mainly intrested in ai ml projects Need a suggestion for a project I''m majoring in AI and Machine Learning. Some ideas I gathered but can't pursue due to complexity:- Automotive Car Police Simulation dating app Handwriting recognition and generator' at position (54, 290).
        Group named 'None' with state 'None' at position (1160, 194).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (1180, 214).
          StaticText named 'None' with state 'DPG: a model to build feature subspace against adversarial patch attack' at position (1176, 830).
          StaticText named 'None' with state 'Machine Learning' at position (1176, 1110).
          StaticText named 'None' with state 'Today, 18:11' at position (2134, 1110).
          StaticText named 'None' with state 'Abstract Adversarial patch attacks in the physical world are a major threat to the application of deep learning. However, current research on adversarial patch defense algorithms focuses on image pre-processing defenses, it has been demonstrated that this defense reduces the classification accuracy of clean images and is unable to defend against physically realizable attacks. In this paper, we propose a defense patch GNN (DPG), using a new perspective for defending against adversarial patch attacks. First, we extract the input image features with the feature extraction to obtain a feature set. Then downsampling the feature set by applying the global average pooling layer to reduce the perturbation of the features by the adversarial patch. Finally, this paper proposes a graph-structured feature subspace to robust the feature performance. In addition, we design an optimization algorithm based on stochastic gradient descent (SGD), which can significantly increase the mode’s generalization ability. We demonstrate empirically the superior robustness of the DPG model on existing adversarial patch attacks. DPG shows without any accuracy loss in the prediction of clean images.' at position (1176, 876).
        Group named 'None' with state 'None' at position (38, 1174).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (58, 1194).
          StaticText named 'None' with state 'Paf-tracker: a novel pre-frame auxiliary and fusion visual tracker' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Siamese-like trackers expose considerable shortcomings in the case of brief occlusion due mainly to the inadequate consideration of the correlation information between adjacent frames. The precision of predicted bounding boxes still has much room for further improvement because the traditional regression loss cannot effectively handle the case where one box contains the other. To address these shortages, the paper proposes a novel pre-frame auxiliary and fusion tracking framework. Within this framework, a retained variable is first introduced to avoid some additional twin branches while retaining the previously obtained deep features of the search frames. Based on such a variable, a pre-frame auxiliary module is constructed to establish the relationship between encoding features and the retained pre-frame information. Furthermore, a decoding fusion module is designed to fuse the generated similarity relationship between the template patch and the search patch and the one between the search frame and previous frames. Moreover, the Efficient IoU (EIoU) loss is employed to increase the precision of predicted bounding boxes by adding three penalty terms for the differences in the center point, length, and width of the two bounding boxes. Finally, the superiority over state-of-the-art methods is verified by numerous tests on visual tracking benchmarks.' at position None.
        Group named 'None' with state 'None' at position (600, 1174).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (620, 1194).
          StaticText named 'None' with state 'Recurrent segmentation meets block models in temporal networks' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract A popular approach to model interactions is to represent them as a network with nodes being the agents and the interactions being the edges. Interactions are often timestamped, which leads to having timestamped edges. Many real-world temporal networks have a recurrent or possibly cyclic behaviour. In this paper, our main interest is to model recurrent activity in such temporal networks. As a starting point we use stochastic block model, a popular choice for modelling static networks, where nodes are split into R groups. We extend the block model to temporal networks by modelling the edges with a Poisson process. We make the parameters of the process dependent on time by segmenting the time line into K segments. We require that only \(H \le K\) different set of parameters can be used. If \(H , then several, not necessarily consecutive, segments must share their parameters, modelling repeating behaviour. We propose two variants where a group membership of a node is fixed over the course of entire time line and group memberships are allowed to vary from segment to segment. We prove that searching for optimal groups and segmentation in both variants is NP-hard. Consequently, we split the problem into 3 subproblems where we optimize groups, model parameters, and segmentation in turn while keeping the remaining structures fixed. We propose an iterative algorithm that requires \(\mathcal {O} \left( KHm + Rn + R^2\,H\right)\) time per iteration, where n and m are the number of nodes and edges in the network. We demonstrate experimentally that the number of required iterations is typically low, the algorithm is able to discover the ground truth from synthetic datasets, and show that certain real-world networks exhibit recurrent behaviour as the likelihood does not deteriorate when H is lowered.' at position None.
        Group named 'None' with state 'None' at position (1160, 1174).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (1180, 1194).
          StaticText named 'None' with state 'Reduced implication-bias logic loss for neuro-symbolic learning' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Integrating logical reasoning and machine learning by approximating logical inference with differentiable operators is a widely used technique in the field of Neuro-Symbolic Learning. However, some differentiable operators could introduce significant biases during backpropagation, which can degrade the performance of Neuro-Symbolic systems. In this paper, we demonstrate that the loss functions derived from fuzzy logic operators commonly exhibit a bias, referred to as Implication Bias. To mitigate this bias, we propose a simple yet efficient method to transform the biased loss functions into Reduced Implication-bias Logic Loss (RILL). Empirical studies demonstrate that RILL outperforms the biased logic loss functions, especially when the knowledge base is incomplete or the supervised training data is insufficient.' at position None.
        Group named 'None' with state 'None' at position (1722, 1174).
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (1742, 1194).
          StaticText named 'None' with state 'DPQ: dynamic pseudo-mean mixed-precision quantization for pruned neural network' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract The ever-increasing layers and hyper-parameters of deep neural network are continuously growing to generate large-scale network by training huge masses of data. However, it is difficult to deploy deep neural network on resource-constrained edge devices. Network mixed-precision quantization is a challenging way to prune and compress deep neural network models while discovering the optimal bit width for each layer. To solve the big challenge, we therefore propose the dynamic pseudo-mean mixed-precision quantization (DPQ) by introducing two-bit scaling factors to compensate errors of quantization. Furthermore, the activation quantization named random parameters clipping (RPC) is proposed. RPC adopts partial activation quantization to reduce loss of accuracy. Therefore, DPQ can dynamically adjust the bit precision of weight quantization according to the distribution of weights. It results in a quantification scheme with strong robustness compared to previous methods. Extensive experiments demonstrate that DPQ achieves 15.43 \(\times\) compression rate of ResNet20 on CIFAR-10 dataset with 0.22% increase in accuracy, and 35.25 \(\times\) compression rate of Resnet56 on SVHN dataset with 0.12% increase in accuracy.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Model-based trajectory stitching for improved behavioural cloning and its applications' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Behavioural cloning (BC) is a commonly used imitation learning method to infer a sequential decision-making policy from expert demonstrations. However, when the quality of the data is not optimal, the resulting behavioural policy also performs sub-optimally once deployed. Recently, there has been a surge in offline reinforcement learning methods that hold the promise to extract high-quality policies from sub-optimal historical data. A common approach is to perform regularisation during training, encouraging updates during policy evaluation and/or policy improvement to stay close to the underlying data. In this work, we investigate whether an offline approach to improving the quality of the existing data can lead to improved behavioural policies without any changes in the BC algorithm. The proposed data improvement approach - Model-Based Trajectory Stitching (MBTS) - generates new trajectories (sequences of states and actions) by ‘stitching’ pairs of states that were disconnected in the original data and generating their connecting new action. By construction, these new transitions are guaranteed to be highly plausible according to probabilistic models of the environment, and to improve a state-value function. We demonstrate that the iterative process of replacing old trajectories with new ones incrementally improves the underlying behavioural policy. Extensive experimental results show that significant performance gains can be achieved using MBTS over BC policies extracted from the original data. Furthermore, using the D4RL benchmarking suite, we demonstrate that state-of-the-art results are obtained by combining MBTS with two existing offline learning methodologies reliant on BC, model-based offline planning (MBOP) and policy constraint (TD3+BC).' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Markov chain importance sampling for minibatches' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract This study investigates importance sampling under the scheme of minibatch stochastic gradient descent, under which the contributions are twofold. First, theoretically, we develop a neat tilting formula, which can be regarded as a general device for asymptotically optimal importance sampling. Second, practically, guided by the formula, we present an effective algorithm for importance sampling which accounts for the effects of minibatches and leverages the Markovian property of the gradients between iterations. Experiments conducted on artificial data confirm that our algorithm consistently delivers superior performance in terms of variance reduction. Furthermore, experiments carried out on real-world data demonstrate that our method, when paired with relatively straightforward models like multilayer perceptron and convolutional neural networks, outperforms in terms of training loss and testing error.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Deep doubly robust outcome weighted learning' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Precision medicine is a framework that adapts treatment strategies to a patient’s individual characteristics and provides helpful clinical decision support. Existing research has been extended to various situations but high-dimensional data have not yet been fully incorporated into the paradigm. We propose a new precision medicine approach called deep doubly robust outcome weighted learning (DDROWL) that can handle big and complex data. This is a machine learning tool that directly estimates the optimal decision rule and achieves the best of three worlds: deep learning, double robustness, and residual weighted learning. Two architectures have been implemented in the proposed method, a fully-connected feedforward neural network and the Deep Kernel Learning model, a Gaussian process with deep learning-filtered inputs. We compare and discuss the performance and limitation of different methods through a range of simulations. Using longitudinal and brain imaging data from patients with Alzheimer’s disease, we demonstrate the application of the proposed method in real-world clinical practice. With the implementation of deep learning, the proposed method can expand the influence of precision medicine to high-dimensional abundant data with greater flexibility and computational power.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Optimizing model-agnostic random subspace ensembles' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract This paper presents a model-agnostic ensemble approach for supervised learning. The proposed approach is based on a parametric version of Random Subspace, in which each base model is learned from a feature subset sampled according to a Bernoulli distribution. Parameter optimization is performed using gradient descent and is rendered tractable by using an importance sampling approach that circumvents frequent re-training of the base models after each gradient descent step. The degree of randomization in our parametric Random Subspace is thus automatically tuned through the optimization of the feature selection probabilities. This is an advantage over the standard Random Subspace approach, where the degree of randomization is controlled by a hyper-parameter. Furthermore, the optimized feature selection probabilities can be interpreted as feature importance scores. Our algorithm can also easily incorporate any differentiable regularization term to impose constraints on these importance scores. We show the good performance of the proposed approach, both in terms of prediction and feature ranking, on simulated and real-world datasets. We also show that PRS can be successfully used for the reconstruction of gene regulatory networks.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Targeted adversarial attacks on wind power forecasts' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract In recent years, researchers proposed a variety of deep learning models for wind power forecasting. These models predict the wind power generation of wind farms or entire regions more accurately than traditional machine learning algorithms or physical models. However, latest research has shown that deep learning models can often be manipulated by adversarial attacks. Since wind power forecasts are essential for the stability of modern power systems, it is important to protect them from this threat. In this work, we investigate the vulnerability of two different forecasting models to targeted, semi-targeted, and untargeted adversarial attacks. We consider a long short-term memory (LSTM) network for predicting the power generation of individual wind farms and a convolutional neural network (CNN) for forecasting the wind power generation throughout Germany. Moreover, we propose the Total Adversarial Robustness Score (TARS), an evaluation metric for quantifying the robustness of regression models to targeted and semi-targeted adversarial attacks. It assesses the impact of attacks on the model’s performance, as well as the extent to which the attacker’s goal was achieved, by assigning a score between 0 (very vulnerable) and 1 (very robust). In our experiments, the LSTM forecasting model was fairly robust and achieved a TARS value of over 0.78 for all adversarial attacks investigated. The CNN forecasting model only achieved TARS values below 0.10 when trained ordinarily, and was thus very vulnerable. Yet, its robustness could be significantly improved by adversarial training, which always resulted in a TARS above 0.46.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Heterogeneous multi-task feature learning with mixed $$\ell _{2,1}$$ regularization' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Data integration is the process of extracting information from multiple sources and jointly analyzing different data sets. In this paper, we propose to use the mixed \(\ell _{2,1}\) regularized composite quasi-likelihood function to perform multi-task feature learning with different types of responses, including continuous and discrete responses. For high dimensional settings, our result establishes the sign recovery consistency and estimation error bounds of the penalized estimates under regularity conditions. Simulation studies and real data analysis examples are provided to illustrate the utility of the proposed method to combine correlated platforms with heterogeneous tasks and perform joint sparse estimation.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'logicDT: a procedure for identifying response-associated interactions between binary predictors' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Interactions between predictors play an important role in many applications. Popular and successful tree-based supervised learning methods such as random forests or logic regression can incorporate interactions associated with the considered outcome without specifying which variables might interact. Nonetheless, these algorithms suffer from certain drawbacks such as limited interpretability of model predictions and difficulties with negligible marginal effects in the case of random forests or not being able to incorporate interactions with continuous variables, being restricted to additive structures between Boolean terms, and not directly considering conjunctions that reveal the interactions in the case of logic regression. We, therefore, propose a novel method called logic decision trees (logicDT) that is specifically tailored to binary input data and helps to overcome the drawbacks of existing methods. The main idea consists of considering sets of Boolean conjunctions, using these terms as input variables for decision trees, and searching for the best performing model. logicDT is also accompanied by a framework for estimating the importance of identified terms, i.e., input variables and interactions between input variables. This new method is compared to other popular statistical learning algorithms in simulations and real data applications. As these evaluations show, logicDT is able to yield high prediction performances while maintaining interpretability.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'A general framework for the practical disintegration of PAC-Bayesian bounds' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract PAC-Bayesian bounds are known to be tight and informative when studying the generalization ability of randomized classifiers. However, they require a loose and costly derandomization step when applied to some families of deterministic models such as neural networks. As an alternative to this step, we introduce new PAC-Bayesian generalization bounds that have the originality to provide disintegrated bounds, i.e., they give guarantees over one single hypothesis instead of the usual averaged analysis. Our bounds are easily optimizable and can be used to design learning algorithms. We illustrate this behavior on neural networks, and we show a significant practical improvement over the state-of-the-art framework.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Automotive fault nowcasting with machine learning and natural language processing' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Automated fault diagnosis can facilitate diagnostics assistance, speedier troubleshooting, and better-organised logistics. Currently, most AI-based prognostics and health management in the automotive industry ignore textual descriptions of the experienced problems or symptoms. With this study, however, we propose an ML-assisted workflow for automotive fault nowcasting that improves on current industry standards. We show that a multilingual pre-trained Transformer model can effectively classify the textual symptom claims from a large company with vehicle fleets, despite the task’s challenging nature due to the 38 languages and 1357 classes involved. Overall, we report an accuracy of more than 80% for high-frequency classes and above 60% for classes with reasonable minimum support, bringing novel evidence that automotive troubleshooting management can benefit from multilingual symptom text classification.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Subspace Adaptation Prior for Few-Shot Learning' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of overfitting when learning new tasks. We demonstrate that this ability is helpful as SAP yields superior or competitive performance in few-shot image classification settings (gains between 0.1% and 3.9% in accuracy). Analysis of the learned subspaces demonstrates that low-dimensional operations often yield high activation strengths, indicating that they may be important for achieving good few-shot learning performance. For reproducibility purposes, we publish all our research code publicly.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Active learning algorithm through the lens of rejection arguments' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Active learning is a paradigm of machine learning which aims at reducing the amount of labeled data needed to train a classifier. Its overall principle is to sequentially select the most informative data points, which amounts to determining the uncertainty of regions of the input space. The main challenge lies in building a procedure that is computationally efficient and that offers appealing theoretical properties; most of the current methods satisfy only one or the other. In this paper, we use the classification with rejection in a novel way to estimate the uncertain regions. We provide an active learning algorithm and prove its theoretical benefits under classical assumptions. In addition to the theoretical results, numerical experiments are carried out on synthetic and non-synthetic datasets. These experiments provide empirical evidence that the use of rejection arguments in our active learning algorithm is beneficial and allows good performance in various statistical situations.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Towards accurate knowledge transfer via target-awareness representation disentanglement' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract Fine-tuning deep neural networks pre-trained on large scale datasets is one of the most practical transfer learning paradigm given limited quantity of training samples. To obtain better generalization, using the starting point as the reference (SPAR), either through weights or features, has been successfully applied to transfer learning as a regularizer. However, due to the domain discrepancy between the source and target task, there exists obvious risk of negative transfer in a straightforward manner of knowledge preserving. In this paper, we propose a novel transfer learning algorithm, introducing the idea of Target-awareness REpresentation Disentanglement ( \(\textrm{TRED}\) ), where the relevant knowledge with respect to the target task is disentangled from the original source model and used as a regularizer during fine-tuning the target model. Two alternative approaches, maximizing Maximum Mean Discrepancy (Max-MMD) and minimizing mutual information (Min-MI) are introduced to achieve the desired disentanglement. Experiments on various real world datasets show that our method stably improves the standard fine-tuning by more than 2% in average. \(\textrm{TRED}\) also outperforms related state-of-the-art transfer learning regularizers such as \(\mathrm {L^2\text {-}SP}\) , \(\textrm{AT}\) , \(\textrm{DELTA}\) , and \(\textrm{BSS}\) . Moreover, our solution is compatible with different choices of disentangling strategies. While the combination of Max-MMD and Min-MI typically achieves higher accuracy, only using Max-MMD can be a preferred choice in applications with low resource budgets.' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          StaticText named 'None' with state 'Differentially private Riemannian optimization' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state 'Today, 18:11' at position None.
          StaticText named 'None' with state 'Abstract In this paper, we study the differentially private empirical risk minimization problem where the parameter is constrained to a Riemannian manifold. We introduce a framework for performing differentially private Riemannian optimization by adding noise to the Riemannian gradient on the tangent space. The noise follows a Gaussian distribution intrinsically defined with respect to the Riemannian metric on the tangent space. We adapt the Gaussian mechanism from the Euclidean space to the tangent space compatible to such generalized Gaussian distribution. This approach presents a novel analysis as compared to directly adding noise on the manifold. We further prove privacy guarantees of the proposed differentially private Riemannian (stochastic) gradient descent using an extension of the moments accountant technique. Overall, we provide utility guarantees under geodesic (strongly) convex, general nonconvex objectives as well as under the Riemannian Polyak-Łojasiewicz condition. Empirical results illustrate the versatility and efficacy of the proposed framework in several applications.' at position None.
      List named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'How To Become An AI All Star. Part I: For Techies - Forbes' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 23:56' at position None.
          StaticText named 'None' with state 'How To Become An AI All Star. Part I: For Techies Forbes' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'Meet Time-LLM: A Reprogramming Machine Learning Framework to Repurpose LLMs for General Time Series Forecasting with the Backbone Language Models Kept Intact - MarkTechPost' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 22:52' at position None.
          StaticText named 'None' with state 'Meet Time-LLM: A Reprogramming Machine Learning Framework to Repurpose LLMs for General Time Series Forecasting with the Backbone Language Models Kept Intact MarkTechPost' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'Daily AI Roundup: Biggest Machine Learning, Robotic And Automation Updates - AiThority' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 22:30' at position None.
          StaticText named 'None' with state 'Daily AI Roundup: Biggest Machine Learning, Robotic And Automation Updates AiThority' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'Why Retailers Need Kinder AI Bots - BizTech Magazine' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 20:52' at position None.
          StaticText named 'None' with state 'Why Retailers Need Kinder AI Bots BizTech Magazine' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state '(Deep) Learning from the Bench: A Conversation on Algorithmic Fairness - Berkman Klein Center' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 20:06' at position None.
          StaticText named 'None' with state '(Deep) Learning from the Bench: A Conversation on Algorithmic Fairness Berkman Klein Center' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'How symmetry can come to the aid of machine learning - Tech Xplore' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 19:02' at position None.
          StaticText named 'None' with state 'How symmetry can come to the aid of machine learning Tech Xplore' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'Max Planck Institute for Informatics and Google are expanding their strategic research partnership on Artificial Intelligence - EurekAlert' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state 'Yesterday, 18:48' at position None.
          StaticText named 'None' with state 'Max Planck Institute for Informatics and Google are expanding their strategic research partnership on Artificial Intelligence EurekAlert' at position None.
      List named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'Weekly AiThority Roundup: Biggest Machine Learning, Robotic And Automation Updates - AiThority' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state '04/02/2024, 22:30' at position None.
          StaticText named 'None' with state 'Weekly AiThority Roundup: Biggest Machine Learning, Robotic And Automation Updates AiThority' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state '[R]Seeking Advice on Adding Pseudo Color to a Car X-ray Image' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state '04/02/2024, 21:33' at position None.
          StaticText named 'None' with state '' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state '[R]Seeking Advice on Adding Pseudo Color to a Car X-ray Image' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state '04/02/2024, 21:33' at position None.
          StaticText named 'None' with state '' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state 'How to detect poisoned data in machine learning datasets - VentureBeat' at position None.
          StaticText named 'None' with state '"machine learning" - Google News' at position None.
          StaticText named 'None' with state '04/02/2024, 21:15' at position None.
          StaticText named 'None' with state 'How to detect poisoned data in machine learning datasets VentureBeat' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position None.
          Image named 'None' with state 'None' at position (0, 1216).
          StaticText named 'None' with state '[P] Chess-GPT, 1000x smaller than GPT-4, plays 1500 Elo chess. We can visualize its internal board state, and it accurately estimates the Elo rating of the players in a game.' at position None.
          StaticText named 'None' with state 'Machine Learning' at position None.
          StaticText named 'None' with state '04/02/2024, 18:06' at position None.
          StaticText named 'None' with state 'gpt-3.5-turbo-instruct's Elo rating of 1800 is chess seemed magical. But it's not! A 100-1000x smaller parameter LLM given a few million games of chess will learn to play at ELO 1500. This model is only trained to predict the next character in PGN strings (1.e4 e5 2.Nf3 …) and is never explicitly given the state of the board or the rules of chess. Despite this, in order to better predict the next character, it learns to compute the state of the board at any point of the game, and learns a diverse set of rules, including check, checkmate, castling, en passant, promotion, pinned pieces, etc. In addition, to better predict the next character it also learns to estimate latent variables such as the Elo rating of the players in the game. We can visualize the internal board state of the model as it's predicting the next character. For example, in this heatmap, we have the ground truth white pawn location on the left, a binary probe output in the middle, and a gradient of probe confidence on the right. We can see the model is extremely confident that no white pawns are on either back rank. https://preview.redd.it/dn8aryvdolgc1.jpg?width=2500&format=pjpg&auto=webp&s=003fe39d8a9bce2cc3271c4c9232c00e4d886aa6 In addition, to better predict the next character it also learns to estimate latent variables such as the ELO rating of the players in the game. More information is available in this post: [https://adamkarvonen.github.io/machine\_learning/2024/01/03/chess-world-models.html](https://adamkarvonen.github.io/machine_learning/2024/01/03/chess-world-models.html) And the code is here: [https://github.com/adamkarvonen/chess\_llm\_interpretability](https://github.com/adamkarvonen/chess_llm_interpretability)' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
        Group named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
          None named 'None' with state 'None' at position None.
    ScrollBar named 'None' with state '0.0' at position (2294, 0).
      ValueIndicator named 'None' with state '0.0' at position (2302, 2).
      Button named 'None' with state 'None' at position None.
      Button named 'None' with state 'None' at position None.
      Button named 'None' with state 'None' at position (2302, 54).
      Button named 'None' with state 'None' at position (2302, 0).
  Toolbar named 'None' with state 'None' at position (0, 0).
    Group named 'None' with state 'None' at position (174, 0).
      Button named '' with state 'None' at position (184, 28).
      Button named '' with state 'None' at position (182, 28).
    CheckBox named 'None' with state '1' at position (244, 0).
    Button named 'None' with state 'None' at position (344, 0).
    CheckBox named 'None' with state '0' at position (444, 0).
    Button named 'None' with state 'None' at position (544, 0).
    Group named 'None' with state 'None' at position (724, 0).
      PopUpButton named 'None' with state 'Latest News' at position (1272, 36).
    CheckBox named 'None' with state '0' at position (2032, 0).
    Button named 'None' with state 'None' at position (2132, 0).
    Group named 'None' with state 'None' at position (2232, 0).
      Button named '' with state 'None' at position (2228, 12).
  Button named 'None' with state 'None' at position (38, 36).
  Button named 'None' with state 'None' at position (118, 36).
    Group named 'None' with state 'None' at position (118, 36).
      Group named 'None' with state 'None' at position (118, 36).
  Button named 'None' with state 'None' at position (78, 36).